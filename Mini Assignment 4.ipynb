{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"http://www.gutenberg.org/files/2147/2147-0.txt\"\n",
    "poestring = urllib.request.urlopen(url).read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start = poestring.find(\"THE GOLD-BUG\")\n",
    "end = poestring.find(\"FOUR BEASTS IN ONE\")\n",
    "goldbugstring = poestring[start:end]\n",
    "directory = \"data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(\"data/goldbug.txt\", \"w\") as f: \n",
    "    f.write(goldbugstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/goldbug.txt\", \"r\") as f: \n",
    "    goldbugstring = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE', 'GOLD-BUG', 'What', 'ho', '!', 'what', 'ho', '!', 'this', 'fellow']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "goldbugtokens = nltk.word_tokenize(goldbugstring)\n",
    "goldbugtokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE', 'GOLD-BUG', 'What', 'ho', '!', 'what', 'ho', '!', 'this', 'fellow'] (for loop technique)\n",
      "['THE', 'GOLD-BUG', 'What', 'ho', '!', 'what', 'ho', '!', 'this', 'fellow'] (list comprehension technique)\n"
     ]
    }
   ],
   "source": [
    "looplist = []\n",
    "for word in goldbugtokens[:10]:\n",
    "    looplist.append(word)\n",
    "print(looplist, \"(for loop technique)\")\n",
    "\n",
    "print([word for word in goldbugtokens[:10]], \"(list comprehension technique)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE', 'GOLD-BUG', 'What', 'ho', 'what', 'ho', 'this', 'fellow']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in goldbugtokens[:10] if word[0].isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ho': 2, 'THE': 1, 'GOLD-BUG': 1, 'What': 1, 'what': 1, 'this': 1, 'fellow': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goldBugRealWordTokensSample = [word for word in goldbugtokens[:10] if word[0].isalpha()]\n",
    "goldBugRealWordFrequenciesSample = nltk.FreqDist(goldBugRealWordTokensSample)\n",
    "goldBugRealWordFrequenciesSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ho      THE GOLD-BUG     What     what     this   fellow \n",
      "       2        1        1        1        1        1        1 \n"
     ]
    }
   ],
   "source": [
    "goldBugRealWordFrequenciesSample.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldbugtokenslowercase = nltk.word_tokenize(goldbugstring.lower())\n",
    "goldbugrealwordtokenslowercase = [word for word in goldbugtokenslowercase if word[0].isalpha()]\n",
    "goldbugrealwordfrequencies = nltk.FreqDist(goldbugrealwordtokenslowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of types: 2751\n",
      "number of tokens: 13629\n",
      "type/token reation: 0.20184899845916796\n"
     ]
    }
   ],
   "source": [
    "print(\"number of types:\", len(goldbugrealwordfrequencies))\n",
    "print(\"number of tokens:\", len(goldbugrealwordtokenslowercase))\n",
    "print(\"type/token reation:\", len(goldbugrealwordfrequencies)/len(goldbugrealwordtokenslowercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the   of  and    i    a   to   in   it  you  was that with   as  for  had   at   he this  but   we \n",
      " 883  465  359  337  329  329  238  213  161  135  130  114  113  113  109  108  103   99   99   98 \n"
     ]
    }
   ],
   "source": [
    "goldbugrealwordfrequencies.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "print(sorted(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     upon        de   jupiter   legrand       one      well      said     massa     could       bug     skull parchment      made     first      time      tree      much       two        us     would \n",
      "       81        73        54        47        38        35        35        34        33        31        27        27        25        24        24        24        23        23        23        22 \n"
     ]
    }
   ],
   "source": [
    "goldbugrealcontentwordtokenslowercase = [word for word in goldbugtokenslowercase \\\n",
    "                                         if word[0].isalpha() and word not in stopwords]\n",
    "goldbugrealcontentwordfrequencies = nltk.FreqDist(goldbugrealcontentwordtokenslowercase)\n",
    "goldbugrealcontentwordfrequencies.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 73 matches:\n",
      " you , ” here interrupted Jupiter ; “ de bug is a goole bug , solid , ebery bi\n",
      "w is your master ? ” “ Why , to speak de troof , massa , him not so berry well\n",
      "aint find nowhar -- dat ’ s just whar de shoe pinch -- my mind is got to be be\n",
      "taint worf while for to git mad about de matter -- Massa Will say noffin at al\n",
      " -- Massa Will say noffin at all aint de matter wid him -- but den what make h\n",
      "a gose ? And den he keep a syphon all de time -- ” “ Keeps a what , Jupiter ? \n",
      "at , Jupiter ? ” “ Keeps a syphon wid de figgurs on de slate -- de queerest fi\n",
      " ” “ Keeps a syphon wid de figgurs on de slate -- de queerest figgurs I ebber \n",
      " syphon wid de figgurs on de slate -- de queerest figgurs I ebber did see . Is\n",
      "vers . Todder day he gib me slip fore de sun up and was gone de whole ob de bl\n"
     ]
    }
   ],
   "source": [
    "goldbugtext = nltk.Text(goldbugtokens)\n",
    "goldbugtext.concordance(\"de\", lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen/1818 Northanger Abbey.txt', 'austen/1815 Emma.txt', 'austen/1811 Sense and Sensibility.txt', 'austen/1805 Lady Susan.txt', 'austen/1813 Pride and Prejudice.txt', 'austen/1790 Love And Freindship.txt', 'austen/1814 Mansfield Park.txt', 'austen/1818 Persuasion.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "files = glob.glob(\"austen/*txt\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"austen/1815 Emma.txt\", \"r\")\n",
    "textString = f.read()\n",
    "f.close()\n",
    "\n",
    "with open(\"austen/1815 Emma.txt\", \"r\") as f: \n",
    "    emmaString = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = emmaString.find(\"Emma\")#search for beginning of text\n",
    "end = emmaString.find(\"FINIS\")#search for end of text\n",
    "emmaText = emmaString[start:end]#create a string with all text\n",
    "import nltk\n",
    "austentokens = nltk.word_tokenize(emmaText)#use tokenizer to create tokenized version of string\n",
    "austentokens[:10]#display 10 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emma', 'Woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', 'She', 'was', 'the']\n",
      "        and         the        with          to          of        Emma   Woodhouse    handsome      clever        rich           a comfortable        home       happy disposition      seemed       unite        some        best   blessings \n",
      "          3           3           2           2           2           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1 \n"
     ]
    }
   ],
   "source": [
    "emmaTextsample = [word for word in austentokens[:50] if word[0].isalpha()]#remove white space\n",
    "print(emmaTextsample)\n",
    "emmafreqdist = nltk.FreqDist(emmaTextsample)\n",
    "emmafreqdist.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Emma Woodhouse handsome clever and rich with a...>\n",
      "Displaying 1 of 1 matches:\n",
      "Emma Woodhouse handsome clever and rich with a comfortable home and h\n"
     ]
    }
   ],
   "source": [
    "concordancetext = nltk.Text(emmaTextsample)\n",
    "print(concordancetext)\n",
    "concordancetext.concordance(\"handsome\", width=100, lines=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Emma', 'Woodhouse'),\n",
       " ('Woodhouse', 'handsome'),\n",
       " ('handsome', 'clever'),\n",
       " ('clever', 'rich'),\n",
       " ('rich', 'comfortable'),\n",
       " ('comfortable', 'home'),\n",
       " ('home', 'happy'),\n",
       " ('happy', 'disposition'),\n",
       " ('disposition', 'seemed'),\n",
       " ('seemed', 'unite')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austenwords = [word for word in austentokens if word[0].isalpha() and word.lower() not in stopwords]#remove whitespace and make lower case\n",
    "from nltk import bigrams, trigrams #import collocate tools\n",
    "tokens = austenwords\n",
    "list(bigrams(tokens))[:10]#list first 10 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import * #import packages with measures for collocates\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "BigramCollectionFinder = nltk.collocations.BigramCollocationFinder.from_words(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A.', 'Em-ma.'),\n",
       " ('A.', 'W.'),\n",
       " ('Abbey', 'CHAPTER'),\n",
       " ('Abbey', 'Mill'),\n",
       " ('Abbey', 'Mr.'),\n",
       " ('Abbey', 'Mrs.'),\n",
       " ('Abbey', 'Oh'),\n",
       " ('Abbey', 'Thank'),\n",
       " ('Abbey', 'especially'),\n",
       " ('Abbey', 'estate')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = BigramCollectionFinder.from_words(tokens) #input Austen text into finder\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)#create list of bigrams and show frequencies\n",
    "sorted(bigram for bigram, score in scored)[:10]#sort nigrams by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Mr.', 'Knightley'), 0.0036850138188018206),\n",
       " (('Mrs.', 'Weston'), 0.0033687626328598734),\n",
       " (('Mr.', 'Elton'), 0.002887510828165606),\n",
       " (('Miss', 'Woodhouse'), 0.0023100086625324843),\n",
       " (('Mr.', 'Weston'), 0.0022000082500309376),\n",
       " (('Frank', 'Churchill'), 0.0019387572703397637),\n",
       " (('Mrs.', 'Elton'), 0.0019387572703397637),\n",
       " (('Mr.', 'Woodhouse'), 0.0018012567547128302),\n",
       " (('Miss', 'Fairfax'), 0.0016637562390858967),\n",
       " (('every', 'thing'), 0.0015950059812724297)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored[0:10]#prints first ten bigrams with their relative frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Frank', 'Churchill'),\n",
       " ('Miss', 'Fairfax'),\n",
       " ('Miss', 'Woodhouse'),\n",
       " ('Mr.', 'Elton'),\n",
       " ('Mr.', 'Knightley'),\n",
       " ('Mr.', 'Weston'),\n",
       " ('Mr.', 'Woodhouse'),\n",
       " ('Mrs.', 'Elton'),\n",
       " ('Mrs.', 'Weston'),\n",
       " ('every', 'thing')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(finder.nbest(bigram_measures.raw_freq, 10))#display top 10 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
