{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"http://www.gutenberg.org/files/2147/2147-0.txt\"\n",
    "poestring = urllib.request.urlopen(url).read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start = poestring.find(\"THE GOLD-BUG\")\n",
    "end = poestring.find(\"FOUR BEASTS IN ONE\")\n",
    "goldbugstring = poestring[start:end]\n",
    "directory = \"data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(\"data/goldbug.txt\", \"w\") as f: \n",
    "    f.write(goldbugstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/goldbug.txt\", \"r\") as f: \n",
    "    goldbugstring = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "\n",
    "goldbugtokens = nltk.word_tokenize(goldbugstring)\n",
    "goldbugtokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looplist = []\n",
    "for word in goldbugtokens[:10]:\n",
    "    looplist.append(word)\n",
    "print(looplist, \"(for loop technique)\")\n",
    "\n",
    "print([word for word in goldbugtokens[:10]], \"(list comprehension technique)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([word for word in goldbugtokens[:10] if word[0].isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldBugRealWordTokensSample = [word for word in goldbugtokens[:10] if word[0].isalpha()]\n",
    "goldBugRealWordFrequenciesSample = nltk.FreqDist(goldBugRealWordTokensSample)\n",
    "goldBugRealWordFrequenciesSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldBugRealWordFrequenciesSample.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldbugtokenslowercase = nltk.word_tokenize(goldbugstring.lower())\n",
    "goldbugrealwordtokenslowercase = [word for word in goldbugtokenslowercase if word[0].isalpha()]\n",
    "goldbugrealwordfrequencies = nltk.FreqDist(goldbugrealwordtokenslowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of types:\", len(goldbugrealwordfrequencies))\n",
    "print(\"number of tokens:\", len(goldbugrealwordtokenslowercase))\n",
    "print(\"type/token reation:\", len(goldbugrealwordfrequencies)/len(goldbugrealwordtokenslowercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldbugrealwordfrequencies.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "print(sorted(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldbugrealcontentwordtokenslowercase = [word for word in goldbugtokenslowercase \\\n",
    "                                         if word[0].isalpha() and word not in stopwords]\n",
    "goldbugrealcontentwordfrequencies = nltk.FreqDist(goldbugrealcontentwordtokenslowercase)\n",
    "goldbugrealcontentwordfrequencies.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldbugtext = nltk.Text(goldbugtokens)\n",
    "goldbugtext.concordance(\"de\", lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(\"austen/*txt\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"austen/1815 Emma.txt\", \"r\")\n",
    "textString = f.read()\n",
    "f.close()\n",
    "\n",
    "with open(\"austen/1815 Emma.txt\", \"r\") as f: \n",
    "    emmaString = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = emmaString.find(\"Emma\")\n",
    "end = emmaString.find(\"FINIS\")\n",
    "emmaText = emmaString[start:end]\n",
    "import nltk\n",
    "austentokens = nltk.word_tokenize(emmaText)\n",
    "austentokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmaTextsample = [word for word in austentokens[:50] if word[0].isalpha()]\n",
    "print(emmaTextsample)\n",
    "emmafreqdist = nltk.FreqDist(emmaTextsample)\n",
    "emmafreqdist.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordancetext = nltk.Text(emmaTextsample)\n",
    "print(concordancetext)\n",
    "concordancetext.concordance(\"handsome\", width=100, lines=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austenwords = [word for word in austentokens if word[0].isalpha() and word.lower() not in stopwords]\n",
    "from nltk import bigrams, trigrams\n",
    "tokens = austenwords\n",
    "list(bigrams(tokens))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "BigramCollectionFinder = nltk.collocations.BigramCollocationFinder.from_words(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollectionFinder.from_words(tokens)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "sorted(bigram for bigram, score in scored)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(finder.nbest(bigram_measures.raw_freq, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(finder.nbest(bigram_measures.raw_freq, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
