{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to open the Austen files from my local directory by using the Python open function. I'm thinking I might need to specify my file structure somehow, but I'm not sure. Let's try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'austen.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-126a0daa5161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"austen.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'austen.zip'"
     ]
    }
   ],
   "source": [
    "file_object = open(\"austen.zip\", \"r\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so I need to figure out how to tell Jupyter my directory. How do I do that I wonder? Right. I just realized the easiest solution is just to put the files in the LLCU612 folder I created. Then I'll have a URL I can call up. OR I could have read the assignment directions and seen I needed to put it on GitHub. Well, same process anyway. Looks like all is well here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "LadySusan = \"https://github.com/kaylinland/llcu612/blob/master/austen/1790%20Love%20And%20Freindship.txt\"\n",
    "SusanString = urllib.request.urlopen(LadySusan).read().decode().strip()\n",
    "print(\"This string has\", len(SusanString), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now I have my LadySusan text. I guess I need to figure out a way to concatenate all of the texts together so that they are one variable. Let's try calling another text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "LoveFreindship = \"https://github.com/kaylinland/llcu612/blob/master/austen/1790%20Love%20And%20Freindship.txt\"\n",
    "LoveFreindshipString = urllib.request.urlopen(LoveFreindship).read().decode().strip()\n",
    "print(\"This string has\", len(LoveFreindship), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I really need to read to the end of the directions. I see that there is a different way to do this that makes more sense, so I'm going to try the method given in the Jupyter notebook for the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "textfiles = glob.glob(\"austen/*txt\")\n",
    "textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfiles = glob.glob(\"/Users/kaylinland/llcu612/austen/*txt\")\n",
    "print(textfiles)\n",
    "textfiles2 = glob.glob(\"*txt\")\n",
    "print(textfiles2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I have all my texts in the variable textfiles. I have no idea why I had to list the entire directory path to get them, but at least it's working. So now I'm going to work through the for loop given in the Jupyter notebook to compare the number of characters in each file. UPDATE: I realized my glob command was searching for an Austen folder inside the Austen folder. Once I deleted the \"Austen\" directory from the file path, I was able to get just the text files without the obnoxious file paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalCharacters = 0\n",
    "for textfile in textfiles2:\n",
    "    f = open(textfile, \"r\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    chars = len(textString)\n",
    "    print(textfile, \"has\", chars, \"characters\")\n",
    "    totalCharacters += chars\n",
    "print(\"total characters: \", totalCharacters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears to be working! So now I think what I need to work on counting things within the text files in Python. To do that, I think I need to change the above code to include the count function instead of the len function. Let's try it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for textfile in textfiles2:\n",
    "    f = open(textfile, \"r\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    count = textString.count(\"love\")\n",
    "    print(\"Love appears\", count, \"times in\", textfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! I can see the occurences of \"love\" in each of the texts. I'm feeling much more comfortable with Python synax, so that's a plus. I think I should try to use the regular expressions given in the assignment to see if I can do some other searches here. So if I want to use the re.findall pattern, I can search for \"love\" and make sure that my results match those with \"count.\" I will try this now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love appears 85 times in 1818 Northanger Abbey.txt\n",
      "Love appears 191 times in 1815 Emma.txt\n",
      "Love appears 124 times in 1811 Sense and Sensibility.txt\n",
      "Love appears 29 times in 1805 Lady Susan.txt\n",
      "Love appears 122 times in 1813 Pride and Prejudice.txt\n",
      "Love appears 48 times in 1790 Love And Freindship.txt\n",
      "Love appears 205 times in 1814 Mansfield Park.txt\n",
      "Love appears 71 times in 1818 Persuasion.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for textfile in textfiles2: \n",
    "    f = open(textfile, \"r\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    regex = re.findall(\"love\", textString, flags=0)\n",
    "    print(\"Love appears\", len(regex), \"times in\", textfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love', 'love']\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "print(regex)\n",
    "print(len(regex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's a lot of love. So this helps me understand that the command \"re.findall\" returns all of the occurences of \"love\" in the texts; outside of the for loop, it returns the last value (Persuasion). Re.findall returns a list of occurences; I need to use len in order to count those occurences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: 1818 Northanger Abbey.txt 9\n",
      "File name: 1815 Emma.txt 30\n",
      "File name: 1811 Sense and Sensibility.txt 39\n",
      "File name: 1805 Lady Susan.txt 2\n",
      "File name: 1813 Pride and Prejudice.txt 32\n",
      "File name: 1790 Love And Freindship.txt 3\n",
      "File name: 1814 Mansfield Park.txt 32\n",
      "File name: 1818 Persuasion.txt 14\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for textfile in textfiles2: \n",
    "    f = open(textfile, \"r\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    regex = re.findall(\"he said\", textString, flags=0)\n",
    "    print(\"File name:\", textfile, len(regex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So I have a list of the occurences of \"he said\" across the texts. This aligns with these values in Voyant, so I think things are working the way they should. I will try the last regex given in the assignment for finding adverbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818 Northanger Abbey.txt 1395\n",
      "['comparatively', 'equally', 'family', 'family', 'greatly', 'merely', 'chiefly', 'occasionally', 'only', 'Sally']\n",
      "1815 Emma.txt 2823\n",
      "['nearly', 'early', 'family', 'particularly', 'hardly', 'mutually', 'highly', 'chiefly', 'only', 'family']\n",
      "1811 Sense and Sensibility.txt 2142\n",
      "['family', 'supply', 'family', 'comfortably', 'merely', 'amply', 'really', 'only', 'only', 'reasonably']\n",
      "1805 Lady Susan.txt 440\n",
      "['affectionately', 'impatiently', 'equally', 'greatly', 'agreeably', 'smoothly', 'family', 'uncommonly', 'only', 'violently']\n",
      "1813 Pride and Prejudice.txt 2289\n",
      "['universally', 'impatiently', 'immediately', 'likely', 'certainly', 'Only', 'merely', 'surely', 'silly', 'suddenly']\n",
      "1790 Love And Freindship.txt 612\n",
      "['Early', 'comply', 'Surely', 'surely', 'considerably', 'lovely', 'shortly', 'tremblingly', 'particularly', 'only']\n",
      "1814 Mansfield Park.txt 2731\n",
      "['only', 'certainly', 'scarcely', 'happily', 'family', 'thoroughly', 'hardly', 'family', 'actually', 'remarkably']\n",
      "1818 Persuasion.txt 1504\n",
      "['Kelly', 'naturally', 'July', 'Precisely', 'originally', 'family', 'accurately', 'family', 'Kelly', 'remarkably']\n"
     ]
    }
   ],
   "source": [
    "for textfile in textfiles2:\n",
    "    f = open(textfile, \"r\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    regex = re.findall(r\"\\w+ly\", textString, flags =0)\n",
    "    print(textfile, len(regex))\n",
    "    print(regex[0:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below was my first attempt at finding the adverbs in context. The code works, but it takes a long time to run and I figured out a faster and more efficient way to do it. Essentially, I created a list showing me where each word started and ended and then created variables for each word using regular expressions with word boundaries to call up the word before the variable wordstart and the word after wordend. This took some fiddling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for textfile in textfiles2: \n",
    "#    f = open(textfile, \"r\")\n",
    "#    textString = f.read()\n",
    "#    f.close()\n",
    "#    for word in re.finditer(r\"\\w+ly\", textString, flags=0):\n",
    "#        #print (\"%s - %s: %s\" % (m.start(), m.end(), m.group(0)) )\n",
    "#        print(r\", textString[word.start()-30:word.end()+30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and perfectly healthy\n"
     ]
    }
   ],
   "source": [
    "wordstart = 466248\n",
    "wordend = 466257\n",
    "\n",
    "theword = textString[wordstart:wordend]\n",
    "\n",
    "#print(textString[wordstart-10:wordend+10])\n",
    "wordbefore = re.findall(r\"\\w+\\b\",textString[:wordstart])[-1]\n",
    "wordafter = re.findall(r\"\\b\\w+\",textString[wordend:])[0]\n",
    "\n",
    "print(wordbefore, theword, wordafter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textcontext(thestring, wordstart, wordend):\n",
    "    theword = thestring[wordstart:wordend]\n",
    "    wordbefore = re.findall(r\"\\w+\\b\", thestring[:wordstart])[-1]\n",
    "    wordafter = re.findall(r\"\\b\\w+\", thestring[wordend:])[0]\n",
    "    context = \"%s %s %s\" % (wordbefore, theword, wordafter)\n",
    "    return context\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, after figuring out how to call up the adverb plus the word before and after it, I wrote a function to perform this task. The function takes a string and the start and end word in that string and creates a variable for the word defined by the start and end word of a string. Then it uses regex to find the word before the start word (by searching for text followed by a word boundary inthe -1 list position. It also finds the word after the start word using the same logic. The context variable eliminates the need to print each variable, giving one variable instead of three printed variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and perfectly healthy'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcontext(textString, wordstart, wordend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for textfile in textfiles2: \n",
    "#    f = open(textfile, \"r\")\n",
    "#    textString = f.read()\n",
    "#    f.close()\n",
    "#    for word in re.finditer(r\"\\w+ly\", textString, flags=0):\n",
    "#        textcontext(textString, word.start(), word.end())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code worked, but it took far too long to save each variable and print them all seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818 Northanger Abbey.txt \n",
      " ['made comparatively obsolete', 'all equally against', 'A family of', 'fine family where', 'and greatly preferred', 'not merely to', 'was chiefly for', 'and occasionally stupid', 'her only to', 'sister Sally could', 'as quickly as'] \n",
      "\n",
      "1815 Emma.txt \n",
      " ['lived nearly twenty', 'very early period', 's family less', 'but particularly of', 'had hardly allowed', 'very mutually attached', 'liked highly esteeming', 'directed chiefly by', 'then only to', 'the family interested', 'and peculiarly interested'] \n",
      "\n",
      "1811 Sense and Sensibility.txt \n",
      " ['The family of', 'to supply her', 'the family of', 'were comfortably spent', 'not merely from', 'was amply provided', 'so really important', 'father only seven', 'had only a', 'might reasonably hope', 'living economically lay'] \n",
      "\n",
      "1805 Lady Susan.txt \n",
      " ['most affectionately urgent', 'I impatiently look', 'affection equally dictated', 'how greatly you', 'more agreeably than', 'goes smoothly the', 'the family are', 'so uncommonly pleasing', 'being only four', 'so violently against', 'less contemptibly weak'] \n",
      "\n",
      "1813 Pride and Prejudice.txt \n",
      " ['truth universally acknowledged', 'wife impatiently _You_', 'Morris immediately that', 'very likely that', 'I certainly _have_', 'daughters Only think', 'go merely on', 'scrupulous surely I', 'all silly and', 'he suddenly addressed', 'mother resentfully since'] \n",
      "\n",
      "1790 Love And Freindship.txt \n",
      " ['Other Early Works', 'I comply with', 'ones Surely that', 'Fathers surely it', 'now considerably softened', 'But lovely as', 'had shortly surpassed', 'too tremblingly alive', 'and particularly to', 'my only fault', 'so gracefully as'] \n",
      "\n",
      "1814 Mansfield Park.txt \n",
      " ['with only seven', 'there certainly are', 'with scarcely any', 'being happily able', 'her family and', 'very thoroughly She', 'could hardly have', 'her family on', 'till actually married', 'temper remarkably easy', 'with merely giving'] \n",
      "\n",
      "1818 Persuasion.txt \n",
      " ['of Kelly nch', 'changed naturally into', 'married July 15', '1791 Precisely such', 'paragraph originally stood', 'his family these', 'most accurately the', 'respectable family in', 'seat Kelly nch', 'been remarkably handsome', 'inferior only to'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for textfile in textfiles2: \n",
    "    f = open(textfile, \"r\")\n",
    "    textString = f.read()\n",
    "    f.close()\n",
    "    adverblist = []\n",
    "    icount = 0\n",
    "    for word in re.finditer(r\"\\w+ly\", textString, flags=0):\n",
    "        adverblist.append(textcontext(textString, word.start(), word.end()))\n",
    "        icount = icount + 1\n",
    "        if icount >10 : break\n",
    "    print (textfile,\"\\n\", adverblist,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, finally, I have a for loop that contains my textcontext function in action. Inside the for loop is an empty list called adverblist with an iterator \"icount\". Then I used the for loop from above to find all the adverbs and within that for loop called the function I wrote textcontext to find the words on either side of the adverbs. These results are added to the list adverblist through the append function. For each group of words that is added, the iterator counter adds 1. Finally, the break command tells python to stop after 10 iterations have been gone through (so that the loop is not running for too long, as happened when I used my earlier code). Finally, I print the textfile name and the adverblist, which gives you the first 10 adverbs in context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
